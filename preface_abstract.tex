\prefacesection{Abstract}
We present a new framework for wavefront sensing for wide-field telescopes. The framework divides the problem into two subproblems that are highly amenable to machine learning and optimization. The first involves making local wavefront estimates with a convolutional neural network. The second involves interpolating the optics wavefront from all the local estimates by minimizing a convex loss function. In this thesis, we develop simulated observations and images from the upcoming Rubin Observatory to refine and assess this framework. Much of this work is also summarized in \cite{2020SPIE11448E..4HT} and \cite{9523024}, although here we describe it in more detail. 

Our unique contributions are as follows. We isolated wavefront sensing problem and decomposed it into two sub-problems. We created benchmark datasets for both sub-problems. We demonstrated a convolutional neural network can predict local wavefront from donut images. We showed that the global wavefront can be interpolated with least squares from the local wavefront estimates. Finally, we developed a wavefront control simulation environment and used it to assess three canonical control strategies.

The algorithm has great practical properties - it is transparent, robust, low latency, and high bandwidth - and achieves stunning performance. In a realistic Rubin mini-survey, the algorithm reduces the total magnitude of the optics wavefront by 66\%, the optics PSF FWHM by 27\%, and increases the Strehl ratio by a factor of 6. The resulting sharper images have the potential to boost the scientific payload for astrophysics and cosmology.